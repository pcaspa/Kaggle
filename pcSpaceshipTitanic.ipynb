{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Spaceship Titanic\n"]},{"cell_type":"code","execution_count":44,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-23T05:20:24.307534Z","iopub.status.busy":"2023-10-23T05:20:24.307175Z","iopub.status.idle":"2023-10-23T05:20:25.732590Z","shell.execute_reply":"2023-10-23T05:20:25.731641Z","shell.execute_reply.started":"2023-10-23T05:20:24.307503Z"},"trusted":true},"outputs":[],"source":["\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Load data"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T05:20:25.734792Z","iopub.status.busy":"2023-10-23T05:20:25.733739Z","iopub.status.idle":"2023-10-23T05:20:25.805422Z","shell.execute_reply":"2023-10-23T05:20:25.804034Z","shell.execute_reply.started":"2023-10-23T05:20:25.734758Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(8693, 14)\n","(4277, 13)\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8693 entries, 0 to 8692\n","Data columns (total 14 columns):\n"," #   Column        Non-Null Count  Dtype  \n","---  ------        --------------  -----  \n"," 0   PassengerId   8693 non-null   object \n"," 1   HomePlanet    8492 non-null   object \n"," 2   CryoSleep     8476 non-null   object \n"," 3   Cabin         8494 non-null   object \n"," 4   Destination   8511 non-null   object \n"," 5   Age           8514 non-null   float64\n"," 6   VIP           8490 non-null   object \n"," 7   RoomService   8512 non-null   float64\n"," 8   FoodCourt     8510 non-null   float64\n"," 9   ShoppingMall  8485 non-null   float64\n"," 10  Spa           8510 non-null   float64\n"," 11  VRDeck        8505 non-null   float64\n"," 12  Name          8493 non-null   object \n"," 13  Transported   8693 non-null   bool   \n","dtypes: bool(1), float64(6), object(7)\n","memory usage: 891.5+ KB\n"]}],"source":["# Files copied locally\n","\n","train = pd.read_csv('sst_train.csv')\n","test = pd.read_csv('sst_test.csv')\n","print(train.shape)\n","print(test.shape)\n","train.info()"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T05:20:25.844870Z","iopub.status.busy":"2023-10-23T05:20:25.844476Z","iopub.status.idle":"2023-10-23T05:20:25.876262Z","shell.execute_reply":"2023-10-23T05:20:25.874848Z","shell.execute_reply.started":"2023-10-23T05:20:25.844794Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>HomePlanet</th>\n","      <th>CryoSleep</th>\n","      <th>Cabin</th>\n","      <th>Destination</th>\n","      <th>Age</th>\n","      <th>VIP</th>\n","      <th>RoomService</th>\n","      <th>FoodCourt</th>\n","      <th>ShoppingMall</th>\n","      <th>Spa</th>\n","      <th>VRDeck</th>\n","      <th>Name</th>\n","      <th>Transported</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0001_01</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>B/0/P</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>39.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Maham Ofracculy</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0002_01</td>\n","      <td>Earth</td>\n","      <td>False</td>\n","      <td>F/0/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>24.0</td>\n","      <td>False</td>\n","      <td>109.0</td>\n","      <td>9.0</td>\n","      <td>25.0</td>\n","      <td>549.0</td>\n","      <td>44.0</td>\n","      <td>Juanna Vines</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0003_01</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>A/0/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>58.0</td>\n","      <td>True</td>\n","      <td>43.0</td>\n","      <td>3576.0</td>\n","      <td>0.0</td>\n","      <td>6715.0</td>\n","      <td>49.0</td>\n","      <td>Altark Susent</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0003_02</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>A/0/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>33.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>1283.0</td>\n","      <td>371.0</td>\n","      <td>3329.0</td>\n","      <td>193.0</td>\n","      <td>Solam Susent</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0004_01</td>\n","      <td>Earth</td>\n","      <td>False</td>\n","      <td>F/1/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>16.0</td>\n","      <td>False</td>\n","      <td>303.0</td>\n","      <td>70.0</td>\n","      <td>151.0</td>\n","      <td>565.0</td>\n","      <td>2.0</td>\n","      <td>Willy Santantines</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8688</th>\n","      <td>9276_01</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>A/98/P</td>\n","      <td>55 Cancri e</td>\n","      <td>41.0</td>\n","      <td>True</td>\n","      <td>0.0</td>\n","      <td>6819.0</td>\n","      <td>0.0</td>\n","      <td>1643.0</td>\n","      <td>74.0</td>\n","      <td>Gravior Noxnuther</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8689</th>\n","      <td>9278_01</td>\n","      <td>Earth</td>\n","      <td>True</td>\n","      <td>G/1499/S</td>\n","      <td>PSO J318.5-22</td>\n","      <td>18.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Kurta Mondalley</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8690</th>\n","      <td>9279_01</td>\n","      <td>Earth</td>\n","      <td>False</td>\n","      <td>G/1500/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>26.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1872.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Fayey Connon</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>8691</th>\n","      <td>9280_01</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>E/608/S</td>\n","      <td>55 Cancri e</td>\n","      <td>32.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>1049.0</td>\n","      <td>0.0</td>\n","      <td>353.0</td>\n","      <td>3235.0</td>\n","      <td>Celeon Hontichre</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8692</th>\n","      <td>9280_02</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>E/608/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>44.0</td>\n","      <td>False</td>\n","      <td>126.0</td>\n","      <td>4688.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12.0</td>\n","      <td>Propsh Hontichre</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8693 rows Ã— 14 columns</p>\n","</div>"],"text/plain":["     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n","0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n","1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n","2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n","3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n","4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n","...          ...        ...       ...       ...            ...   ...    ...   \n","8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n","8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n","8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n","8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n","8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n","\n","      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n","0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n","1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n","2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n","3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n","4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n","...           ...        ...           ...     ...     ...                ...   \n","8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n","8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n","8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n","8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n","8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n","\n","      Transported  \n","0           False  \n","1            True  \n","2           False  \n","3           False  \n","4            True  \n","...           ...  \n","8688        False  \n","8689        False  \n","8690         True  \n","8691        False  \n","8692         True  \n","\n","[8693 rows x 14 columns]"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["# Quick view of training data\n","train"]},{"cell_type":"markdown","metadata":{},"source":["## Data Cleaning"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T05:20:25.879376Z","iopub.status.busy":"2023-10-23T05:20:25.879057Z","iopub.status.idle":"2023-10-23T05:20:25.949276Z","shell.execute_reply":"2023-10-23T05:20:25.947976Z","shell.execute_reply.started":"2023-10-23T05:20:25.879349Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(8693, 16)\n","(8693,)\n","(4277, 16)\n"]}],"source":["\n","def split_cabin(x):\n","  if len(str(x).split('/')) < 3:\n","    return ['Missing', 0, \"Missing\"]\n","  else:   \n","    return str(x).split('/')\n","\n","\n","def cleandata(dfin): \n","    \n","    df = dfin.copy()\n","    \n","    df['CryoSleep'] = pd.to_numeric(df['CryoSleep'])\n","    df['CryoSleep'] = df['CryoSleep'].astype(bool)\n","    df['VIP'] = pd.to_numeric(df['VIP'])\n","    df['VIP'] = df['VIP'].astype(bool)\n","    df[['group', 'groupno']] = df['PassengerId'].str.split('_', expand=True)\n","    df['group'] = pd.to_numeric(df['group'])\n","    df['groupno'] = pd.to_numeric(df['groupno'])\n","    df.drop(['PassengerId'], axis=1, inplace=True)\n","    # apply(lambda is inefficient\n","    df['TempCabin'] = df['Cabin'].apply(lambda x: split_cabin(x))\n","    df['Deck'] = df['TempCabin'].apply(lambda x: x[0])\n","    df['Room'] = df['TempCabin'].apply(lambda x: x[1])\n","    df['Side'] = df['TempCabin'].apply(lambda x: x[2])\n","    df['Room'] = pd.to_numeric(df['Room'])\n","    df.drop(['TempCabin', 'Cabin'], axis=1, inplace=True)  \n","    \n","    return df\n","#train[train['Cabin'].isnull()]\n","train_clean=cleandata(train)\n","test_clean=cleandata(test)\n","y_train = train_clean.Transported\n","train_clean.drop(['Transported'], axis=1, inplace=True)\n","\n","print(train_clean.shape)\n","print(y_train.shape)\n","print(test_clean.shape)\n"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["\n","if 1==2: # Activate\n","\n","    import sweetviz as sv\n","\n","    # Create the report\n","    report = sv.compare([train, \"Training Data\"], [test, \"Test Data\"])\n","\n","    # Display the report within the Jupyter Notebook\n","    report.show_notebook()\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Pre Processing"]},{"cell_type":"code","execution_count":57,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(8693, 29)\n","(4277, 29)\n"]}],"source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","\n","# General function for preprocessing\n","\n","def preprocess_data(df, cols_to_exclude=None, exclude_output_cols=None, log_normalize_cols=None, one_hot_encode_cols=None, imput_strategy='mean'):\n","    # Copy the original DataFrame to avoid modifying it\n","    processed_df = df.copy()\n","\n","    # Exclude specified columns from the output\n","    if exclude_output_cols:\n","        processed_df = processed_df.drop(columns=exclude_output_cols, errors='ignore')\n","\n","    # Log normalization for selected columns\n","    if log_normalize_cols:\n","        for col in log_normalize_cols:\n","            if col in processed_df.columns:\n","                processed_df[col] = np.log1p(processed_df[col])\n","\n","    \n","\n","    # Exclude specified columns from scaling, imputing, and one-hot encoding\n","    if cols_to_exclude:\n","        cols_to_process = [col for col in processed_df.columns if col not in cols_to_exclude]\n","        numeric_cols = processed_df[cols_to_process].select_dtypes(include=['number']).columns\n","        imputer = SimpleImputer(strategy=imput_strategy)\n","        scaler = StandardScaler()\n","        processed_df[numeric_cols] = scaler.fit_transform(imputer.fit_transform(processed_df[numeric_cols]))\n","\n","    # One-hot encode selected columns\n","    if one_hot_encode_cols:\n","        processed_df = pd.get_dummies(processed_df, columns=one_hot_encode_cols)\n","    \n","    \n","    # Fill missing values in non-numeric columns (excluding boolean columns) with 'Missing'\n","    # but only if there are missing values to begin with\n","    non_numeric_cols = processed_df.select_dtypes(exclude=['number', 'bool']).columns\n","    for col in non_numeric_cols:\n","        if processed_df[col].isnull().any():\n","            processed_df[col] = processed_df[col].fillna('Missing')\n","\n","\n","    return processed_df\n","\n","\n","\n","#imput_strategy = mean, median, most_frequent\n","#cols_to_exclude= exclude from imputer and scaler\n","X_train = preprocess_data(train_clean,  cols_to_exclude=['PassengerId'], exclude_output_cols=['Name'], log_normalize_cols=['RoomService','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck'], one_hot_encode_cols=['Destination','HomePlanet','Deck','Side'],imput_strategy='mean')\n","X_test = preprocess_data(test_clean,  cols_to_exclude=['PassengerId'], exclude_output_cols=['Name'], log_normalize_cols=['RoomService','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck'], one_hot_encode_cols=['Destination','HomePlanet','Deck','Side'],imput_strategy='mean')\n","\n","\n","print(X_train.shape)\n","print(X_test.shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["## EDA Tools"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["if 1==2: # Activate\n","\n","    import sweetviz as sv\n","\n","    report = sv.compare([X_train, \"Training Data\"], [X_test, \"Test Data\"])\n","\n","    # Display the report within the Jupyter Notebook\n","    report.show_notebook()"]},{"cell_type":"code","execution_count":51,"metadata":{"trusted":true},"outputs":[],"source":["if 1==2: # Activate\n","    import pygwalker as pyg\n","    pyg.walk(X_train)"]},{"cell_type":"markdown","metadata":{},"source":["## Modelling"]},{"cell_type":"code","execution_count":52,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import GridSearchCV \n","from sklearn.model_selection import RandomizedSearchCV \n","from sklearn.metrics import precision_score, accuracy_score, recall_score\n","from sklearn.metrics import mean_squared_error\n","#from sklearn.base import BaseEstimator, ClassifierMixin\n","from xgboost import XGBClassifier\n","import tensorflow as tf\n"]},{"cell_type":"code","execution_count":58,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Metrics accuracy- 0.9339698608075463, recall- 0.9321608040201005, precision- 0.9364387333639284\n","Mean Squared Error: 0.0660301391924537\n"]}],"source":["# Basic XGBoost\n","\n","xgb = XGBClassifier(random_state =1)\n","\n","\n","xgb.fit(X_train,y_train)\n","y_pred = xgb.predict(X_train)\n","\n","\n","accuracy = accuracy_score(y_train,y_pred) # Accuracy is the ratio of correctly predicted observation to the total\n","precision = precision_score(y_train,y_pred) # Precision is the ratio of correctly predicted positive observations to the total predicted positives. \n","recall = recall_score(y_train,y_pred) # Recall is the ratio of correctly predicted positive observations to the all actual positives. \n","print(f'Metrics accuracy- {accuracy}, recall- {recall}, precision- {precision}')\n","\n","mse = mean_squared_error(y_train,y_pred)\n","print(\"Mean Squared Error:\", mse)\n","\n","#Metrics accuracy- 0.9312090187507189, recall- 0.9323892188213796, precision- 0.9311131386861314\n","#Metrics accuracy- 0.9339698608075463, recall- 0.9321608040201005, precision- 0.9364387333639284"]},{"cell_type":"code","execution_count":54,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 10000 candidates, totalling 50000 fits\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Windows PC\\OneDrive\\Desktop\\Python\\Kaggle\\pcSpaceshipTitanic.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Windows%20PC/OneDrive/Desktop/Python/Kaggle/pcSpaceshipTitanic.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m#clf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Windows%20PC/OneDrive/Desktop/Python/Kaggle/pcSpaceshipTitanic.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m#best_clf_xgb = clf_xgb.fit(X_train,y_train)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Windows%20PC/OneDrive/Desktop/Python/Kaggle/pcSpaceshipTitanic.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#clf_performance(best_clf_xgb,'XGB')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Windows%20PC/OneDrive/Desktop/Python/Kaggle/pcSpaceshipTitanic.ipynb#X14sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m clf_xgb_rnd \u001b[39m=\u001b[39m RandomizedSearchCV(xgb, param_distributions \u001b[39m=\u001b[39m param_grid, n_iter \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m, cv \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, verbose \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Windows%20PC/OneDrive/Desktop/Python/Kaggle/pcSpaceshipTitanic.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m best_clf_xgb_rnd \u001b[39m=\u001b[39m clf_xgb_rnd\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Windows%20PC/OneDrive/Desktop/Python/Kaggle/pcSpaceshipTitanic.ipynb#X14sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m y_pred \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mpredict(X_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Windows%20PC/OneDrive/Desktop/Python/Kaggle/pcSpaceshipTitanic.ipynb#X14sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_train,y_pred)\n","File \u001b[1;32mc:\\Users\\Windows PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\Windows PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\Windows PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1807\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1808\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1809\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1810\u001b[0m         ParameterSampler(\n\u001b[0;32m   1811\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1812\u001b[0m         )\n\u001b[0;32m   1813\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Windows PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Windows PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n","File \u001b[1;32mc:\\Users\\Windows PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n","File \u001b[1;32mc:\\Users\\Windows PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Windows PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","# XGBoost with grid search\n","\n","\"\"\"param_grid = {\n","    'n_estimators': [20, 50, 100, 250, 500,1000],\n","    'colsample_bytree': [0.2, 0.5, 0.7, 0.8, 1],\n","    'max_depth': [2, 5, 10, 15, 20, 25, None],\n","    'reg_alpha': [0, 0.5, 1],\n","    'reg_lambda': [1, 1.5, 2],\n","    'subsample': [0.5,0.6,0.7, 0.8, 0.9],\n","    'learning_rate':[.01,0.1,0.2,0.3,0.5, 0.7, 0.9],\n","    'gamma':[0,.01,.1,1,10,100],\n","    'min_child_weight':[0,.01,0.1,1,10,100],\n","    'sampling_method': ['uniform', 'gradient_based']\n","}\n","\"\"\"\n","\n","\n","\n","param_grid = {\n","    'n_estimators': [10, 20, 30],\n","    'colsample_bytree': [0.3, 0.5, 0.7],\n","    'max_depth': [ 10, 15, 20],\n","    'reg_alpha': [0, 0.5],\n","    'reg_lambda': [1.5, 2,2.5],\n","    'subsample': [ 0.8, 0.9,1,1.1],\n","    'learning_rate':[0.001,0.01,0.1],\n","    'gamma':[.1,1,10],\n","    'min_child_weight':[1,10,100],\n","    'sampling_method': ['uniform']\n","}\n","\n","\n","#clf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n","#best_clf_xgb = clf_xgb.fit(X_train,y_train)\n","#clf_performance(best_clf_xgb,'XGB')\n","clf_xgb_rnd = RandomizedSearchCV(xgb, param_distributions = param_grid, n_iter = 10000, cv = 5, verbose = True, n_jobs = -1)\n","best_clf_xgb_rnd = clf_xgb_rnd.fit(X_train,y_train)\n","y_pred = xgb.predict(X_train)\n","\n","\n","accuracy = accuracy_score(y_train,y_pred)\n","precision = precision_score(y_train,y_pred)\n","recall = recall_score(y_train,y_pred)\n","print(f'Metrics accuracy- {accuracy}, recall- {recall}, precision- {precision}')\n","\n","print('Best Score: ' + str(best_clf_xgb_rnd.best_score_))\n","print('Best Parameters: ' + str(best_clf_xgb_rnd.best_params_))\n","\n","\n","#Best Score: 0.7876492779536142\n","#Best Parameters: {'subsample': 0.9, 'sampling_method': 'uniform', 'reg_lambda': 2, 'reg_alpha': 0, 'n_estimators': 20, 'min_child_weight': 10, 'max_depth': 15, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.5}\n","#Best Score: 0.7901786074692081\n","#Best Parameters: {'subsample': 0.9, 'sampling_method': 'uniform', 'reg_lambda': 1.5, 'reg_alpha': 0, 'n_estimators': 10, 'min_child_weight': 10, 'max_depth': 15, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.5}\n","#Fitting 5 folds for each of 100 candidates, totalling 500 fits\n","#Best Score: 0.7884539412953094\n","#Best Parameters: {'subsample': 0.8, 'sampling_method': 'uniform', 'reg_lambda': 2, 'reg_alpha': 0.5, 'n_estimators': 10, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.5}\n","#Mean Squared Error: 0.1741631197515242\n","#Metrics accuracy- 0.9312090187507189, recall- 0.9323892188213796, precision- 0.9311131386861314\n","#Metrics accuracy- 0.9339698608075463, recall- 0.9321608040201005, precision- 0.9364387333639284\n","#Best Parameters: {'subsample': 0.9, 'sampling_method': 'uniform', 'reg_lambda': 2, 'reg_alpha': 0, 'n_estimators': 10, 'min_child_weight': 10, 'max_depth': 20, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.5}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# tensor flow with grid search\n","X_train = X_train * 1\n","\n","# Custom wrapper for Keras model\n","class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n","    def __init__(self, model, optimizer='adam', neurons1=8, neurons2=8, activation='relu', epochs=50, batch_size=10):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.neurons1 = neurons1\n","        self.neurons2 = neurons2\n","        self.activation = activation\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self._estimator_type = \"classifier\"\n","\n","    def fit(self, X, y):\n","        X = np.array(X)\n","        y = np.array(y)\n","        self.model = self.model(optimizer=self.optimizer, neurons1=self.neurons1, neurons2=self.neurons2, activation=self.activation)\n","        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n","        return self\n","\n","    def predict(self, X):\n","        X = np.array(X)\n","        return (self.model.predict(X) > 0.5).astype(int)\n","\n","    def score(self, X, y):\n","        X = np.array(X)\n","        y = np.array(y)\n","        predictions = self.predict(X)\n","        return accuracy_score(y, predictions)\n","\n","# Function to create the Keras model\n","def create_model(optimizer='adam', neurons1=8, neurons2=8, activation='relu'):\n","    model = tf.keras.models.Sequential()\n","    model.add(tf.keras.layers.Dense(neurons1, input_dim=X_train.shape[1], activation=activation))\n","    model.add(tf.keras.layers.Dense(neurons2, activation=activation))\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Use sigmoid for binary classification\n","    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","\n","# Use the wrapper with GridSearchCV\n","model = KerasClassifierWrapper(model=create_model)\n","\n","param_grid = {\n","    'optimizer': ['SGD', 'Adam'],\n","    'neurons1': [8, 16, 32],\n","    'neurons2': [8, 16, 32],\n","    'activation': ['relu', 'tanh'],\n","    'batch_size': [10, 20],\n","    'epochs': [30, 50]\n","}\n","\n","param_grid = {\n","    'optimizer': ['SGD'],\n","    'neurons1': [8],\n","    'neurons2': [8],\n","    'activation': ['relu', 'tanh'],\n","    'batch_size': [10],\n","    'epochs': [30]\n","}\n","\n","\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', n_jobs=1, cv=3)\n","grid_result = grid.fit(X_train, y_train)\n","\n","y_pred = grid_result.predict(X_train)\n","\n","\n","accuracy = accuracy_score(y_train,y_pred)\n","precision = precision_score(y_train,y_pred)\n","recall = recall_score(y_train,y_pred)\n","print(f'Metrics accuracy- {accuracy}, recall- {recall}, precision- {precision}')\n","\n","# Print the best results\n","print(f\"Best Accuracy: {grid_result.best_score_} using {grid_result.best_params_}\")\n","\n","\n","\n","#Best Accuracy: nan using {'activation': 'relu', 'batch_size': 10, 'epochs': 30, 'neurons1': 8, 'neurons2': 8, 'optimizer': 'SGD'}\n","\n","#Mean Squared Error: 0.19544461060623491\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n","Metrics accuracy- 0.9012998964684229, recall- 0.8951576062128825, precision- 0.9075961093098657\n","Best Parameters: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n","Best Score: 0.7798265077015414\n"]}],"source":["\n","import numpy as np\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.datasets import make_classification\n","\n","# RandomForest with grid search\n","\n","# Define the RandomForestClassifier\n","rf_clf = RandomForestClassifier()\n","\n","# Hyperparameters to be checked in the GridSearchCV\n","param_grid = {\n","    'n_estimators': [10, 50, 100, 200],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'bootstrap': [True, False]\n","}\n","\n","# Create the GridSearchCV model\n","grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, \n","                           cv=5, n_jobs=-1, verbose=2)\n","\n","# Fit the GridSearchCV model\n","grid_search.fit(X_train, y_train)\n","\n","y_pred = grid_search.predict(X_train)\n","\n","\n","accuracy = accuracy_score(y_train,y_pred)\n","precision = precision_score(y_train,y_pred)\n","recall = recall_score(y_train,y_pred)\n","print(f'Metrics accuracy- {accuracy}, recall- {recall}, precision- {precision}')\n","\n","# Print the best parameters and the corresponding score\n","print(\"Best Parameters:\", grid_search.best_params_)\n","print(\"Best Score:\", grid_search.best_score_)\n","\n","# If you wish to use the best estimator found:\n","best_rf_clf = grid_search.best_estimator_\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n","Metrics accuracy- 0.7946623720234671, recall- 0.8042485153037917, precision- 0.7914138008541245\n","Best parameters found:  {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n","Training accuracy with best parameters:  0.9012998964684229\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","# GradientBoosting with grid search\n","\n","# Create a GradientBoostingClassifier\n","gb_clf = GradientBoostingClassifier()\n","\n","# Define a parameter grid to search\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'learning_rate': [0.01, 0.1, 0.2],\n","    'max_depth': [3, 4, 5],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'subsample': [0.8, 0.9, 1.0]\n","}\n","\n","# Set up GridSearchCV\n","grid_search_gb = GridSearchCV(estimator=gb_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n","\n","# Fit the model\n","grid_search_gb.fit(X_train, y_train)\n","\n","\n","y_pred = grid_search_gb.predict(X_train)\n","\n","\n","accuracy = accuracy_score(y_train,y_pred)\n","precision = precision_score(y_train,y_pred)\n","recall = recall_score(y_train,y_pred)\n","print(f'Metrics accuracy- {accuracy}, recall- {recall}, precision- {precision}')\n","\n","# Get the best parameters\n","best_params = grid_search.best_params_\n","print('Best parameters found: ', best_params)\n","\n","# Get the best estimator\n","best_gb_clf = grid_search.best_estimator_\n","\n","# Make predictions on the training data\n","train_predictions = best_gb_clf.predict(X_train)\n","\n","\n","# Calculate accuracy on the training data\n","train_accuracy = accuracy_score(y_train, train_predictions)\n","print('Training accuracy with best parameters: ', train_accuracy)\n","\n","\n","#Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n","#Metrics accuracy- 0.7946623720234671, recall- 0.8042485153037917, precision- 0.7914138008541245\n","#Best parameters found:  {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n","#Training accuracy with best parameters:  0.9012998964684229"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[False False  True ...  True  True  True]\n"]}],"source":["# Make predictions simple XGBoost\n","\n","xgb.fit(X_train,y_train)\n","\n","# Make predictions\n","predictions = xgb.predict(X_test).astype(bool)\n","\n","test_sub = test.copy()\n","\n","test_sub['Transported'] = predictions\n","\n","\n","test_df_sub = test_sub[['PassengerId', 'Transported']]\n","\n","test_df_sub\n","\n","test_df_sub.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'best_clf_xgb' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Windows PC\\OneDrive\\Desktop\\Python\\Kaggle\\pcspaceshiptitanic.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Windows%20PC/OneDrive/Desktop/Python/Kaggle/pcspaceshiptitanic.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Windows%20PC/OneDrive/Desktop/Python/Kaggle/pcspaceshiptitanic.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predictions \u001b[39m=\u001b[39m best_clf_xgb\u001b[39m.\u001b[39mpredict(X_test)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Windows%20PC/OneDrive/Desktop/Python/Kaggle/pcspaceshiptitanic.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Update the 'Survived' column in the original DataFrame\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Windows%20PC/OneDrive/Desktop/Python/Kaggle/pcspaceshiptitanic.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test[\u001b[39m'\u001b[39m\u001b[39mTransported\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m predictions\n","\u001b[1;31mNameError\u001b[0m: name 'best_clf_xgb' is not defined"]}],"source":["# Make predictions XGB/Grid\n","predictions = best_clf_xgb.predict(X_test).astype(int)\n","\n","test_sub = test.copy()\n","\n","test_sub['Transported'] = predictions\n","\n","\n","test_df_sub = testsub[['PassengerId', 'Transported']]\n","\n","test_df_sub\n","\n","test_df_sub.to_csv('submission_xgb2.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Make predictions Tensor Flow\n","predictions = grid.predict(X_test).astype(int)\n","\n","test_sub = test.copy()\n","\n","test_sub['Transported'] = predictions\n","\n","\n","test_df_sub = test_sub[['PassengerId', 'Transported']]\n","\n","test_df_sub\n","\n","test_df_sub.to_csv('submission_tf.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","# Make predictions RANDOM FOREST\n","predictions = grid_search.predict(X_test).astype(bool)\n","\n","test_sub = test.copy()\n","\n","test_sub['Transported'] = predictions\n","\n","\n","test_df_sub = test_sub[['PassengerId', 'Transported']]\n","\n","test_df_sub\n","\n","test_df_sub.to_csv('submission_rf.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Make predictions GRADIENT BOOST\n","\n","predictions = grid_search_gb.predict(X_test).astype(bool)\n","\n","test_sub = test.copy()\n","\n","test_sub['Transported'] = predictions\n","\n","\n","test_df_sub = test_sub[['PassengerId', 'Transported']]\n","\n","test_df_sub\n","\n","test_df_sub.to_csv('submission_gb.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Save, Load Model"]},{"cell_type":"markdown","metadata":{},"source":["#save load model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pickle\n","\n","with open('gradientboosted.pkl', 'wb') as f: \n","  pickle.dump(fit_models['gb'], f)\n","\n","with open('gradientboosted.pkl', 'rb') as f: \n","  reloaded_model = pickle.load(f)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":4}
